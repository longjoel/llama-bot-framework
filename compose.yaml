### LET THE MAYHEM BEGIN
### WANT MORE BOTS? CLONE ALICE!
services:
 
  #enable this service if you want a local IRC server to play in.
  # ergo:
  #   init: true
  #   image: ghcr.io/ergochat/ergo:stable
  #   ports:
  #     - "6667:6667/tcp"
  #     - "6697:6697/tcp"
  #   volumes:
  #     - ./ircd:/ircd
  #   deploy:
  #     placement:
  #       constraints:
  #         - "node.role == manager"
  #     restart_policy:
  #       condition: on-failure
  #     replicas: 1
  #   restart: unless-stopped
  #   networks:
  #     - llama-net

  alice:
    image: longjoel/llama-bot-fw
    container_name: alice
    command: node ./src/v3.js
    environment:
      OLLAMA_SERVER: http://localhost:11434
      IRC_SERVER: vault
      IRC_NICK: alice
      MODEL: llama3.2
      PROMPT: "you are Alice."
      OLLAMA_HOIST: false
      ACTIVITY: proactive
    volumes:
      - ./ollama:/root/.ollama
      - .:/app
    networks:
      - llama-net

  # bob:
  #   image: localhost/longjoel/llama-bot-fw
  #   container_name: bob
  #   command: node ./src/v3.js
  #   environment:
  #     OLLAMA_SERVER: http://localhost:11434
  #     IRC_SERVER: vault
  #     IRC_NICK: bob
  #     MODEL: llama3.2
  #     PROMPT: "bob loves to spend time outdoors."
  #     OLLAMA_HOIST: true
  #     ACTIVITY: proactive
  #   volumes:
  #     - ./ollama:/root/.ollama
  #     - .:/app
  #   networks:
  #     - llama-net

  # peep:
  #   image: localhost/longjoel/llama-bot-fw
  #   container_name: peep
  #   command: node ./src/v3.js
  #   environment:
  #     OLLAMA_SERVER: http://localhost:11434
  #     IRC_SERVER: vault
  #     IRC_NICK: peep
  #     MODEL: llama3.2
  #     PROMPT: "you are peep. act like a pet llama named peep. Do not respond in english. Just grunts."
  #     OLLAMA_HOIST: true
  #     ACTIVITY: proactive
  #   volumes:
  #     - ./ollama:/root/.ollama
  #     - .:/app
  #   networks:
  #     - llama-net
networks:
  llama-net: